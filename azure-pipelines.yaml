name: Azure Pipelines

# Start with a minimal pipeline that you can customize to build and deploy your code.
# Add steps that build, run tests, deploy, and more:
# https://aka.ms/yaml
trigger:
- main

# ToDo: Replace the agent pool name, if you are using Udacity Cloud lab. 
# Otherwise, comment out the line below. 
pool: myAgentPool

variables:
  python.version: '3.7.6'
  # ToDo: Replace the service connection name as used in the DevOps project settings
  azureServiceConnectionId: 'myServiceConnection'
  # Project root folder. Point to the folder containing manage.py file.
  projectRoot: $(System.DefaultWorkingDirectory)
  # Environment name
  environmentName: 'test-vm'

stages:
#--------------------------------------------#  
# BUILD STAGE
#--------------------------------------------#    
- stage: Build
  jobs:
  - job: BuildInfrastructure
    steps:
    # #--------------------------------------------#  
    # # Use Terraform to create the Infrastructure      
    # # Install Terraform on the pipeline agent 
    # - task: JasonBJohnson.azure-pipelines-tasks-terraform.azure-pipelines-tasks-terraform-installer.TerraformInstaller@0
    #   displayName: 'Terraform installation'
    #   inputs:
    #     terraformVersion: '1.6.3'

    # # Run Terraform Init on the pipeline agent 
    # # ToDo: Replace the resource group name, storage account name, and container name below
    # # Run Terraform Init on the pipeline agent 
    # - task: TerraformTaskV4@4
    #   displayName: 'Terraform init'
    #   inputs:
    #     provider: 'azurerm'
    #     command: 'init'
    #     workingDirectory: '$(System.DefaultWorkingDirectory)/terraform/environments/test'
    #     backendServiceArm: 'myServiceConnection'
    #     backendAzureRmResourceGroupName: 'Azuredevops'
    #     backendAzureRmStorageAccountName: 'tfstate2458128476'
    #     backendAzureRmContainerName: 'tfstate'
    #     backendAzureRmKey: "$(access_key)"
    
    # # Run Terraform validate on the pipeline agent 
    # - task: TerraformTaskV4@4
    #   displayName: Terraform validate
    #   inputs:
    #     provider: 'azurerm'
    #     command: 'validate'

    # # OPTIONAL - This step is needed only if your Terraform VM uses an SSH key pair for login and you want your pipeline agent to connect to it. 
    # # Generate an SSH key pair in your local/AZ Cloud shell. Use the public key in the Terraform VM module. 
    # # Install public key and private key file to the pipeline agent, using the task below. 
    # # ToDo: Change the inputs value below
    # # - task: InstallSSHKey@0
    # #   inputs:
    # #     knownHostsEntry: 'KNOWN_HOSTS_STRING' # variable value
    # #     sshPublicKey: 'PUBLIC_KEY'            # variable value
    # #     sshKeySecureFile: 'id_rsa' # Use secure file feature in the pipeline library UI to save the "id_rsa" file, as mentioned here: https://learn.microsoft.com/en-us/azure/devops/pipelines/library/secure-files?view=azure-devops#add-a-secure-file
    
    # # - task: DownloadSecureFile@1
    # #  name: udacity_public_key
    # #  displayName: 
    # #  inputs:
    # #   secureFile: 

    # # Run Terraform Apply
    # - task: TerraformTaskV4@4
    #   displayName: Terraform apply
    #   inputs:
    #     provider: 'azurerm'
    #     command: 'apply'
    #     workingDirectory: '$(System.DefaultWorkingDirectory)/terraform/environments/test'
    #     environmentServiceNameAzureRM: '$(azureServiceConnectionId)'

    # # ToDo: Change the workingDirectory path, as applicable to you
    # # Destroy the resources in Azure by running a separate pipeline. 
    # - task: TerraformTaskV3@3
    #   displayName: Terraform destroy
    #   inputs:
    #     provider: 'azurerm'
    #     command: 'destroy'
    #     workingDirectory: '$(System.DefaultWorkingDirectory)/terraform/environments/test'
    #     environmentServiceNameAzureRM: '$(azureServiceConnectionId)'

    #--------------------------------------------#   
    # Install Node.js
    - task: NodeTool@0
      displayName: 'Install Node.js'
      inputs:
        versionSource: 'spec'
        versionSpec: '16.x'  # Use a modern version of Node.js

    # Verify npm installation
    - task: CmdLine@2
      displayName: Verify npm
      inputs:
        script: 'npm --version'

    # Install Newman
    - task: CmdLine@2
      displayName: Install Newman
      inputs:
        script: 'npm install -g newman'
        workingDirectory: $(System.DefaultWorkingDirectory)
        
    # Postman Data Validation Test Suite    
    # ToDo: Verify the working directory
    - task: CmdLine@2
      displayName: Run Data Validation Tests
      continueOnError: true
      inputs:
        script: 'newman run TestSuite.Data-Validation.json -e Test.environment.json --reporters cli,junit --reporter-junit-export TEST-DataValidation.xml'
        workingDirectory: '$(System.DefaultWorkingDirectory)/automatedtesting/postman'
    # Postman Regression Test Suite    
    # ToDo: Verify the working directory
    - task: CmdLine@2
      displayName: Run Regression Tests
      continueOnError: true
      inputs:
        script: 'newman run TestSuite.Regression.json -e Test.environment.json --reporters cli,junit --reporter-junit-export TEST-Regression.xml'
        workingDirectory: '$(System.DefaultWorkingDirectory)/automatedtesting/postman'
    # Postman - Publish Results 
    # ToDo: Complete the task as explained here: https://learn.microsoft.com/en-us/azure/devops/pipelines/tasks/test/publish-test-results?view=azure-devops&tabs=trx%2Cyaml#yaml-snippet
    - task: PublishTestResults@2
      inputs:
        testResultsFormat: 'JUnit'
        testResultsFiles: '**/TEST-*.xml'
        searchFolder: '$(System.DefaultWorkingDirectory)' # string. Search folder. Default: $(System.DefaultWorkingDirectory).
        mergeTestResults: true
        testRunTitle: 'Postman Tests'

    #--------------------------------------------#
    # Selenium (UI) Test Suite - Archive the package  
    # "ArchiveFiles@2" picks up the web package and archives it.
    - task: ArchiveFiles@2
      displayName: 'Archive UI Tests'
      inputs:
        rootFolderOrFile: '$(System.DefaultWorkingDirectory)/automatedtesting/selenium'
        includeRootFolder: false
        archiveType: 'zip'
        archiveFile: '$(Build.ArtifactStagingDirectory)/$(Build.BuildId)-uitests.zip'
    # Selenium Test Suite - Publish the package  
    - publish: $(Build.ArtifactStagingDirectory)/$(Build.BuildId)-uitests.zip   # Same as the archiveFile artifact above. 
      displayName: 'Upload Package'
      artifact: drop-uitests

    #--------------------------------------------#    
    # FakeRestAPI - Archive
    # ToDo: Complete the ArchiveFiles@2 task and publish step 
    - task: ArchiveFiles@2
      displayName: 'Archive FakeRestAPI'
      inputs:
        rootFolderOrFile: '$(System.DefaultWorkingDirectory)/automatedtesting/jmeter/fakerestapi'
        includeRootFolder: false
        archiveType: 'zip'
        archiveFile: '$(Build.ArtifactStagingDirectory)/$(Build.BuildId)-fakerestapi.zip'
    - publish: $(Build.ArtifactStagingDirectory)/$(Build.BuildId)-fakerestapi.zip
      displayName: 'Upload Package'
      artifact: drop-fakerestapi

    #--------------------------------------------#  
    # JMeter (Performance) Test Suite - Archive
    # ToDo: Complete the ArchiveFiles@2 task and publish step 
    - task: ArchiveFiles@2
      displayName: 'Archive PerformanceTestSuite'
      inputs:
        rootFolderOrFile: '$(System.DefaultWorkingDirectory)/automatedtesting/jmeter'
        includeRootFolder: false
        archiveType: 'zip'
        archiveFile: '$(Build.ArtifactStagingDirectory)/$(Build.BuildId)-perftests.zip'
    # JMeter Test Suite - Publish    
    - publish: $(Build.ArtifactStagingDirectory)/$(Build.BuildId)-perftests.zip
      displayName: 'Upload Package'
      artifact: drop-perftests

#--------------------------------------------#  
# DEPLOYMENT STAGE
#--------------------------------------------#    
- stage: Deploy
  jobs:
  #--------------------------------------------#  
  # Deploy FakeRestAPI Web App
  - deployment: FakeRestAPI
    pool: myAgentPool
    environment: "$(environmentName)"
    strategy:
      runOnce:
        deploy:
          steps:
          # Deploy the Azure Web App
          - task: AzureWebApp@1
            displayName: 'Deploy Azure Web App'
            inputs:
              azureSubscription: '$(azureServiceConnectionId)'
              appName: 'myApplication-AppService'
              appType: webApp
              package: '$(Pipeline.Workspace)/drop-fakerestapi/$(Build.BuildId)-fakerestapi.zip'

          #--------------------------------------------#  
          # Run JMeter test suite against the App Service
          - task: CmdLine@2
            displayName: Run Endurance and Stress Tests with JMeter
            inputs:
              script: |
                # Install necessary packages
                sudo apt-get update && sudo apt-get install -y curl zip default-jre default-jdk
                
                # Download JMeter
                wget "https://apache.mirrors.lucidnetworks.net//jmeter/binaries/apache-jmeter-5.2.1.tgz"
                tar -xf apache-jmeter-5.2.1.tgz
                
                # Unzip performance test files from artifact
                unzip -o "$(Build.BuildId)-perftests.zip"
                
                # Set JMeter directory and log paths
                JMETER_DIR="./apache-jmeter-5.2.1/bin"
                LOG_DIR="jmeter-logs"
                
                # Create directories for logs
                mkdir -p ${LOG_DIR}/endurance-test
                mkdir -p ${LOG_DIR}/stress-test
                
                # Run the Endurance Test Suite
                ${JMETER_DIR}/jmeter -n -t "automatedtesting/jmeter/EnduranceTestSuite.jmx" -Jresdir="automatedtesting/jmeter/test_data.csv" -l ${LOG_DIR}/endurance-test/endurance-test.csv -e -f -o ${LOG_DIR}/endurance-test/html -j ${LOG_DIR}/endurance-test/jmeter.log
                
                # Display Endurance Test Logs
                echo "JMETER LOG ENDURANCE TEST"
                cat ${LOG_DIR}/endurance-test/jmeter.log

                # Run the Stress Test Suite
                ${JMETER_DIR}/jmeter -n -t "automatedtesting/jmeter/StressTestSuite.jmx" -Jresdir="automatedtesting/jmeter/test_data.csv" -l ${LOG_DIR}/stress-test/stress-test.csv -e -f -o ${LOG_DIR}/stress-test/html -j ${LOG_DIR}/stress-test/jmeter.log
                
                # Display Stress Test Logs
                echo "JMETER LOG STRESS TEST"
                cat ${LOG_DIR}/stress-test/jmeter.log
              workingDirectory: $(Pipeline.Workspace)/drop-perftests

          #--------------------------------------------#  
          # Archive JMeter test logs as build artifacts
          - task: ArchiveFiles@2
            displayName: Archive JMeter Log Files
            inputs:
              rootFolderOrFile: "$(Pipeline.Workspace)/drop-perftests/log/jmeter"
              includeRootFolder: false
              archiveType: "zip"
              archiveFile: "$(Pipeline.Workspace)/drop-perftests/log/jmeter-$(Build.BuildId).zip"
              verbose: true

          #--------------------------------------------#  
          # Publish JMeter test logs as build artifacts
          - task: PublishBuildArtifacts@1
            displayName: Publish JMeter Artifacts
            inputs:
              PathtoPublish: '$(Pipeline.Workspace)/drop-perftests/log/jmeter'
              ArtifactName: 'jmeter-results'
              publishLocation: 'Container'


  #--------------------------------------------#  
  # Selenium | Functional UI Tests
  # ToDo: 
  - deployment: VMDeploy
    displayName: Selenium Tests
    environment:
      name: "$(environmentName)"       # ToDo: Change/provide a name
      resourceType: VirtualMachine
      tags: web
    strategy:
      runOnce:
        deploy:
          steps:
          - download: current
            artifact: drop-uitests
            patterns: '**/*.zip'
            
          - task: Bash@3
            inputs:
              targetType: 'inline'
              script: |
                #! /bin/bash

                sudo apt install python3.7
                sudo apt-get install python3.7-venv
                sudo apt-get install python3-pip -y
                sudo apt-get install unzip -y
                sudo apt-get install -y chromium-browser

                # Set up app directory
                cd ~/
                DIR=/home/azureuser/app
                if [ ! -d "$DIR" ]; then
                    mkdir app
                fi

                mv /home/azureuser/azagent/_work/1/drop-uitests/$(Build.BuildId)-uitests.zip app
                cd app
                unzip -o $(Build.BuildId)-uitests.zip

                # Download the chromedriver version for the installed Chromium version (130.0.6723.116)
                CHROME_VERSION="130.0.6723.116"
                FILE=/home/azureuser/app/chromedriver_linux64.zip
                if [ ! -f "$FILE" ]; then
                    # Fetch the latest chromedriver version for Chrome 130
                    LATEST=$(wget -q -O - "https://chromedriver.storage.googleapis.com/LATEST_RELEASE_130")
                    wget https://chromedriver.storage.googleapis.com/$LATEST/chromedriver_linux64.zip
                    unzip -o chromedriver_linux64.zip
                    sudo rm -f /usr/local/bin/chromedriver  # Remove existing symlink if it exists
                    sudo ln -s $PWD/chromedriver /usr/local/bin/chromedriver
                fi

                # Add chromedriver to PATH
                export PATH=$PATH:/home/azureuser/app

                # Make virtual environment
                python3 -m venv venv
                source venv/bin/activate

                # Install selenium
                pip3 install selenium

                # Starting Selenium tests using the virtual environment's Python
                echo "Starting Selenium Tests"
                python3 add_remove_from_cart.py >> selenium.log
                echo "Completed Selenium Tests. Check selenium.log for results."
